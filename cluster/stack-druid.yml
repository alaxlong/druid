version: '3.7'

networks:
  druid-net:
    external: true

volumes: 
  zk-data:
  zk-logs:
  data-mysql:
  data-broker:
  data-coordinator:
  data-historical:
  data-overlord:
  data-router:
  data-redis:
  data-kafka:
  data-middlemanager:
  data-grafana:

services:

  # zookeeper:
  #   image: zookeeper:3.5.5
  #   hostname: zookeeper
  #   ports:
  #     - 2181:2181
  #   environment:
  #     ZOO_MY_ID: 1
  #     ZOO_SERVERS: server.1=0.0.0.0:2888:3888
  #     ZOO_INIT_LIMIT: 10000
  #   volumes:      
  #     - zk-data:/data
  #     - zk-logs:/datalog
  #   deploy:
  #     replicas: 1
  #     placement:
  #       constraints: 
  #         - node.labels.node.type == manager
  #     restart_policy:
  #       condition: on-failure
  #   networks: 
  #     - druid-net

  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.1   
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 10
      ZOOKEEPER_SYNC_LIMIT: 5
    ports:
      - 2181:2181
    volumes:
      - zk-data:/var/lib/zookeeper/data
      - zk-logs:/var/lib/zookeeper/log
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
    
  kafka-broker:
    image: wurstmeister/kafka:2.12-2.2.0
    hostname: kafka-broker
    depends_on:
      - zookeeper
    ports:           
      - target: 19092
        published: 19092
        protocol: tcp
        mode: host        
      - 7777:7777                 
    environment:  # todo : fix broker id generation
      BROKER_ID_COMMAND: "curl http://169.254.169.254/latest/meta-data/local-ipv4 | awk -F '.' '{print $$1 + $$2 + $$3 + $$4}'"
      HOSTNAME_COMMAND: "curl http://169.254.169.254/latest/meta-data/public-hostname"
      # HOSTNAME_COMMAND: "wget -t3 -T2 -qO-  http://169.254.169.254/latest/meta-data/local-ipv4"      
      # HOSTNAME_COMMAND: "docker info | grep ^Name: | cut -d' ' -f 2"      
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181        
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:19092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://:9092,EXTERNAL://_{HOSTNAME_COMMAND}:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL      
      KAFKA_LOG_DIRS: /kafka/logs
      KAFKA_LOG_RETENTION_HOURS: 8
      KAFKA_LOG_ROLL_HOURS: 4       
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_RESERVED_BROKER_MAX_ID : 1020   
      KAFKA_AUTO_CREATE_TOPICS_ENABLE : "false"
      KAFKA_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS: 30
      KAFKA_LEADER_IMBALANCE_PER_BROKER_PERCENTAGE: 0
      KAFKA_OFFSETS_RETENTION_CHECK_INTERVAL_MS: 30000   
      KAFKA_JMX_PORT : 7777      
      EXTRA_ARGS: -javaagent:/root/prometheus/jmx_prometheus_javaagent-0.11.0.jar=7777:/root/prometheus/prom-jmx-agent-config.yml
    volumes:
      - data-kafka:/kafka
      - ~/aws:/root/.aws    
      - ~/conf-prometheus:/root/prometheus/  
    deploy:
      mode: global
      placement:
        constraints: 
          - node.labels.node.type == kafka
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
 
  connect:
    image: confluentinc/cp-kafka-connect:5.2.1    
    hostname: connect
    depends_on:
      - zookeeper
      - kafka-broker
    ports:
      - target: 18083
        published: 18083        
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka-broker:9092"
      CONNECT_REST_PORT: 18083
      CONNECT_GROUP_ID: "s3-sink"
      CONNECT_CONFIG_STORAGE_TOPIC: "__s3-sink-config"
      CONNECT_OFFSET_STORAGE_TOPIC: "__s3-sink-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "__s3-sink-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1      
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
      CONNECT_PLUGIN_PATH: /usr/share/java 
      CONNECT_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"              
      KAFKA_HEAP_OPTS: "-Xms10g -Xmx25g"
    volumes:
      - ~/aws:/root/.aws
      - ~/conf-kconnect:/usr/share/java
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == kafka
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  redis:
    image: redis:5.0.3-alpine3.8
    hostname: redis
    ports:
      - 6379:6379
    volumes:
      - data-redis:/data
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  mysql:
    image: mysql:5.7
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: 'yes'
      MYSQL_DATABASE: druid
      MYSQL_USER: druid
      MYSQL_PASSWORD: diurd
    command:
      - --character-set-server=utf8
      - --collation-server=utf8_unicode_ci
    volumes:
      - data-mysql:/var/lib/mysql
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
    networks: 
      - druid-net

  historical:    
    image: canelmas/druid:0.2.0    
    command: historical
    ports:
      - 8083:8083
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-historical:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
    deploy:
      mode: global
      placement:
        constraints: 
          - node.labels.node.type == data      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  broker:
    image: canelmas/druid:0.2.0  
    command: broker
    ports:
      - 8082:8082
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-broker:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql      
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  coordinator:
    image: canelmas/druid:0.2.0
    command: coordinator
    ports:
      - 8081:8081
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-coordinator:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  overlord:
    image: canelmas/druid:0.2.0
    command: overlord
    ports:
      - 8090:8090
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-overlord:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
      
  router:
    image: canelmas/druid:0.2.0
    command: router
    ports:
      - 8888:8888
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-router:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
      - coordinator
      - broker
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
  
  middleManager:
    image: canelmas/druid:0.2.0
    command: middleManager
    ports:
      - 8091:8091
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-middlemanager:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
      - broker
    deploy:
      replicas: 2
      placement:
        constraints: 
          - node.labels.node.type == ingestion
    networks: 
      - druid-net
  
  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - 18080:8080
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
    networks: 
      - druid-net
  
  superset:
    image: amancevice/superset:0.28.1
    ports:
      - 18088:8088    
    deploy:
      replicas: 0
      placement:
        constraints: 
          - node.labels.node.type == query
    networks: 
      - druid-net
    
  prometheus:
    image: prom/prometheus:v2.10.0    
    ports:
      - 9090:9090
    depends_on:
      - zookeeper
      - broker
    volumes:    
      - ~/conf-prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query
    networks: 
      - druid-net

  grafana:
    image: grafana/grafana:6.2.1    
    ports:
      - 3000:3000
    depends_on:
      - prometheus
    volumes:
      - data-grafana:/var/lib/grafana
    environment:
      GF_SECURITY_ADMIN_USER: byob
      GF_SECURITY_ADMIN_PASSWORD: byob
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query
    networks: 
      - druid-net

  data-producer:
    image: canelmas/data-producer:2.0.3
    depends_on:
      - redis
    environment:
      PERIOD_IN_MS: 3000
      NUM_OF_USERS: 5
      SESSION_PER_USER: 3
      EVENTS_PER_SESSION: 25
      TOPICS_USERS: users
      TOPICS_EVENTS: events
      # CREATE_TOPICS: "events:10:1,users:5:1"
      RUN_MODE: default
      EVENT_SCENARIO: random
      NODE_OPTIONS: --max_old_space_size=4096
      REDIS_HOST: redis
      REDIS_PORT: 6379    
      BROKERS: kafka-broker:9092
      VERBOSE: "false"
      NODE_ENV: production
      APP_IDS: "LovelyApp,LoveliestApp,HappyApp,HappiestApp"
      DATE_FORMAT: YYYY-MM-DDTHH:mm:ssZ
    deploy:
      replicas: 0
      placement:
        constraints: 
          - node.labels.node.type == producer      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net