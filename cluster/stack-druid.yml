version: '3.7'

networks:
  druid-net:
    external: true

volumes: 
  zk-data:
  zk-logs:
  data-mysql:
  data-broker:
  data-coordinator:
  data-historical:
  data-overlord:
  data-router:
  data-redis:
  data-kafka:
  data-middlemanager:

services:

  # zookeeper:
  #   image: zookeeper:3.4.14
  #   hostname: zookeeper
  #   ports:
  #     - 2181:2181
  #   environment:
  #     ZOO_MY_ID: 1
  #     ZOO_SERVERS: server.1=0.0.0.0:2888:3888
  #     ZOO_INIT_LIMIT: 2000
  #   volumes:      
  #     - zk-data:/data
  #     - zk-logs:/datalog
  #   deploy:
  #     replicas: 1
  #     placement:
  #       constraints: 
  #         - node.labels.node.type == manager
  #     restart_policy:
  #       condition: on-failure
  #   networks: 
  #     - druid-net

  zookeeper:
    image: confluentinc/cp-zookeeper:5.1.0    
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - 2181:2181
    volumes:
      - zk-data:/var/lib/zookeeper/data
      - zk-logs:/var/lib/zookeeper/log
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
    
  kafka-broker: # no swarm support for confluent kafka
    image: wurstmeister/kafka:2.12-2.2.0
    hostname: kafka-broker
    depends_on:
      - zookeeper
    ports:
      - 19092:19092
    environment:  # todo : fix broker id generation
      BROKER_ID_COMMAND: "curl http://169.254.169.254/latest/meta-data/local-ipv4 | awk -F '.' '{print $$1 + $$2 + $$3 + $$4}'"
      HOSTNAME_COMMAND: "curl http://169.254.169.254/latest/meta-data/public-hostname"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181        
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL://:19092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://:9092,EXTERNAL://_{HOSTNAME_COMMAND}:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL      
      KAFKA_LOG_DIRS: /kafka/logs
      KAFKA_LOG_RETENTION_HOURS: 2
      KAFKA_LOG_ROLL_HOURS: 1        
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_RESERVED_BROKER_MAX_ID : 1020     
    volumes:
      - data-kafka:/kafka
      - ~/aws:/root/.aws      
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == kafka
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
 
  connect:
    image: confluentinc/cp-kafka-connect:5.2.1    
    hostname: connect
    depends_on:
      - zookeeper
      - kafka-broker
    ports:
      - 18083:18083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka-broker:9092"
      CONNECT_REST_PORT: 18083
      CONNECT_GROUP_ID: "s3-sink"
      CONNECT_CONFIG_STORAGE_TOPIC: "__s3-sink-config"
      CONNECT_OFFSET_STORAGE_TOPIC: "__s3-sink-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "__s3-sink-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1      
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
      CONNECT_PLUGIN_PATH: /usr/share/java 
      CONNECT_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"            
    volumes:
      - ~/aws:/root/.aws
      - ~/conf-kconnect:/usr/share/java
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == kafka
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  redis:
    image: redis:5.0.3-alpine3.8
    hostname: redis
    ports:
      - 6379:6379
    volumes:
      - data-redis:/data
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == data      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  mysql:
    image: mysql:5.7
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: 'yes'
      MYSQL_DATABASE: druid
      MYSQL_USER: druid
      MYSQL_PASSWORD: diurd
    command:
      - --character-set-server=utf8
      - --collation-server=utf8_unicode_ci
    volumes:
      - data-mysql:/var/lib/mysql
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
    networks: 
      - druid-net

  historical:    
    image: canelmas/druid:0.2.0    
    command: historical
    ports:
      - 8083:8083
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-historical:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
    deploy:
      mode: global
      placement:
        constraints: 
          - node.labels.node.type == data      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  broker:
    image: canelmas/druid:0.2.0  
    command: broker
    ports:
      - 8082:8082
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-broker:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql      
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  coordinator:
    image: canelmas/druid:0.2.0
    command: coordinator
    ports:
      - 8081:8081
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-coordinator:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net

  overlord:
    image: canelmas/druid:0.2.0
    command: overlord
    ports:
      - 8090:8090
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-overlord:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
      
  router:
    image: canelmas/druid:0.2.0
    command: router
    ports:
      - 8888:8888
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-router:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
      - coordinator
      - broker
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net
  
  middleManager:
    image: canelmas/druid:0.2.0
    command: middleManager
    ports:
      - 8091:8091
    volumes:
      - ~/conf-druid:/opt/druid/conf
      - data-middlemanager:/opt/druid/var
    depends_on:
      - zookeeper
      - mysql
      - broker
    deploy:
      mode: global
      placement:
        constraints: 
          - node.labels.node.type == data
    networks: 
      - druid-net
  
  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - 18080:8080
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == manager
    networks: 
      - druid-net
  
  superset:
    image: amancevice/superset:0.28.1
    ports:
      - 18088:8088    
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.labels.node.type == query
    networks: 
      - druid-net

  data-producer:
    image: canelmas/data-producer:1.2.1
    environment:
      PERIOD_IN_MS: 5000
      NUM_OF_USERS: 10
      SESSION_PER_USER: 3
      EVENTS_PER_SESSION: 20
      TOPICS_USERS: users
      TOPICS_EVENTS: events
      RUN_MODE: 0
      EVENT_SCENARIO: random
      NODE_OPTIONS: --max_old_space_size=4096
      REDIS_HOST: redis
      REDIS_PORT: 6379
      BROKER: kafka-broker:9092
      VERBOSE: "false"
      NODE_ENV: production
      APP_IDS: "LovelyApp,LoveliestApp,HappyApp,HappiestApp"
    deploy:
      replicas: 0
      placement:
        constraints: 
          - node.labels.node.type == producer      
      restart_policy:
        condition: on-failure
    networks: 
      - druid-net